{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVFfeZVYkLol"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install git+https://github.com/deepset-ai/haystack.git#egg=farm-haystack[colab]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
      ],
      "metadata": {
        "id": "JNJyqPxc_8uq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In-Memory Document Store\n",
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "\n",
        "document_store = InMemoryDocumentStore()"
      ],
      "metadata": {
        "id": "8_E1lV1mAAHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b1adcd4-9beb-47fd-cf72-6d0a14adafdb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.modeling.utils:Using devices: CUDA:0 - Number of GPUs: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "uFR-IZwdADGJ",
        "outputId": "c7594767-d403-47f7-dd21-65a29c779828"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bbe05935-3dd0-4c37-aa07-1938d68e949f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bbe05935-3dd0-4c37-aa07-1938d68e949f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving QG using t5 model.csv to QG using t5 model (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['QG using t5 model.csv']))\n",
        "df=df.drop('Unnamed: 0',axis=1)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "35uwscvZAGlA",
        "outputId": "c395700c-7fc3-4533-df1b-97afc55a8297"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           keyphrase  \\\n",
              "0                  transfer learning   \n",
              "1  natural language processing (nlp)   \n",
              "2                                nlp   \n",
              "3                       text-to-text   \n",
              "4             language understanding   \n",
              "5             pretraining objectives   \n",
              "6                             corpus   \n",
              "7                      summarization   \n",
              "8                 question answering   \n",
              "\n",
              "                                                                           context  \\\n",
              "0  ['Transfer learning, where a model is first pre-trained on a data-rich task ...   \n",
              "1  ['Transfer learning, where a model is first pre-trained on a data-rich task ...   \n",
              "2  ['In this paper, we explore the landscape of transfer learning techniques fo...   \n",
              "3  ['In this paper, we explore the landscape of transfer learning techniques fo...   \n",
              "4  ['Our systematic study compares pretraining objectives, narchitectures, unla...   \n",
              "5  ['Our systematic study compares pretraining objectives, narchitectures, unla...   \n",
              "6  ['By combining the insights from our exploration with scale and our new “Col...   \n",
              "7  ['By combining the insights from our exploration with scale and our new “Col...   \n",
              "8  ['By combining the insights from our exploration with scale and our new “Col...   \n",
              "\n",
              "                                                                          question  \n",
              "0         What has emerged as a powerful technique in natural language processing?  \n",
              "1  What did the paper introduce to explore the landscape of transfer learning t...  \n",
              "2                   What has the effectiveness of transfer learning given rise to?  \n",
              "3            What do we do to facilitate future work on transfer learning for NLP?  \n",
              "4    What do systematic studies compare on dozens of language understanding tasks?  \n",
              "5    What do systematic studies compare on dozens of language understanding tasks?  \n",
              "6                                            What are some benchmarks nwe achieve?  \n",
              "7                                            What are some benchmarks nwe achieve?  \n",
              "8                                            What are some benchmarks nwe achieve?  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c359a9f-2ed3-4ef6-8474-ac625284f57e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keyphrase</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>transfer learning</td>\n",
              "      <td>['Transfer learning, where a model is first pre-trained on a data-rich task ...</td>\n",
              "      <td>What has emerged as a powerful technique in natural language processing?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>natural language processing (nlp)</td>\n",
              "      <td>['Transfer learning, where a model is first pre-trained on a data-rich task ...</td>\n",
              "      <td>What did the paper introduce to explore the landscape of transfer learning t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nlp</td>\n",
              "      <td>['In this paper, we explore the landscape of transfer learning techniques fo...</td>\n",
              "      <td>What has the effectiveness of transfer learning given rise to?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>text-to-text</td>\n",
              "      <td>['In this paper, we explore the landscape of transfer learning techniques fo...</td>\n",
              "      <td>What do we do to facilitate future work on transfer learning for NLP?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>language understanding</td>\n",
              "      <td>['Our systematic study compares pretraining objectives, narchitectures, unla...</td>\n",
              "      <td>What do systematic studies compare on dozens of language understanding tasks?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>pretraining objectives</td>\n",
              "      <td>['Our systematic study compares pretraining objectives, narchitectures, unla...</td>\n",
              "      <td>What do systematic studies compare on dozens of language understanding tasks?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>corpus</td>\n",
              "      <td>['By combining the insights from our exploration with scale and our new “Col...</td>\n",
              "      <td>What are some benchmarks nwe achieve?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>summarization</td>\n",
              "      <td>['By combining the insights from our exploration with scale and our new “Col...</td>\n",
              "      <td>What are some benchmarks nwe achieve?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>question answering</td>\n",
              "      <td>['By combining the insights from our exploration with scale and our new “Col...</td>\n",
              "      <td>What are some benchmarks nwe achieve?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c359a9f-2ed3-4ef6-8474-ac625284f57e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c359a9f-2ed3-4ef6-8474-ac625284f57e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c359a9f-2ed3-4ef6-8474-ac625284f57e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.utils import clean_wiki_text, convert_files_to_docs, fetch_archive_from_http\n",
        "document_store.delete_all_documents()\n",
        "docs = []\n",
        "for i in df['context']:\n",
        "  docs.append({'content':i})\n",
        "print(docs[:])\n",
        "# Now, let's write the docs to our DB.\n",
        "document_store.write_documents(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAnLSDwZAZPp",
        "outputId": "aa7c950b-bfc7-41c4-a567-e01bceb9d2a6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:haystack.document_stores.memory:DEPRECATION WARNINGS: \n",
            "                1. delete_all_documents() method is deprecated, please use delete_documents method\n",
            "                For more details, please refer to the issue: https://github.com/deepset-ai/haystack/issues/1045\n",
            "                \n",
            "INFO:haystack.document_stores.base:Duplicate Documents: Document with id '38d44c154443032074664b80c667671' already exists in index 'document'\n",
            "INFO:haystack.document_stores.base:Duplicate Documents: Document with id 'edbc99799fb9be68387e77036a3f0948' already exists in index 'document'\n",
            "INFO:haystack.document_stores.base:Duplicate Documents: Document with id 'edbc99799fb9be68387e77036a3f0948' already exists in index 'document'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).', 'In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\"}, {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).']\"}, {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\"}, {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.']\"}, {'content': \"['Our systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks.']\"}, {'content': \"['Our systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks.']\"}, {'content': \"['By combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks covering summarization, question answering, ntext classification, and more.']\"}, {'content': \"['By combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks covering summarization, question answering, ntext classification, and more.']\"}, {'content': \"['By combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks covering summarization, question answering, ntext classification, and more.']\"}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import TfidfRetriever\n",
        "retriever = TfidfRetriever(document_store=document_store)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3elzrW6xAkPR",
        "outputId": "1229c53d-3b00-4998-eee9-e0229f3c23ac"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:haystack.nodes.retriever.sparse:Found 6 candidate paragraphs from 6 docs in DB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import FARMReader\n",
        "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)"
      ],
      "metadata": {
        "id": "c9TdgkQuBOkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.pipelines import ExtractiveQAPipeline\n",
        "pipe = ExtractiveQAPipeline(reader, retriever)"
      ],
      "metadata": {
        "id": "3m01jhaFBu3Z"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = []\n",
        "for i in df['question']:\n",
        "  answers.append(pipe.run(query = i))"
      ],
      "metadata": {
        "id": "LsME6tNkB9WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers"
      ],
      "metadata": {
        "id": "IwjiGXxrAvyp",
        "outputId": "48f682f8-8cc1-4376-842c-657cc6f2f042",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'query': 'What has emerged as a powerful technique in natural language processing?',\n",
              "  'no_ans_gap': 9.496152400970459,\n",
              "  'answers': [<Answer {'answer': 'Transfer learning', 'type': 'extractive', 'score': 0.9725081920623779, 'context': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful t\", 'offsets_in_document': [{'start': 2, 'end': 19}], 'offsets_in_context': [{'start': 2, 'end': 19}], 'document_id': 'd739f09f9bab640e5cec953a5b98bd6a', 'meta': {}}>,\n",
              "   <Answer {'answer': 'Transfer learning', 'type': 'extractive', 'score': 0.9364281296730042, 'context': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful t\", 'offsets_in_document': [{'start': 2, 'end': 19}], 'offsets_in_context': [{'start': 2, 'end': 19}], 'document_id': '62577fb39bdcb637b47e823dabf6c45b', 'meta': {}}>,\n",
              "   <Answer {'answer': 'transfer learning', 'type': 'extractive', 'score': 0.6614342927932739, 'context': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language pro\", 'offsets_in_document': [{'start': 45, 'end': 62}], 'offsets_in_context': [{'start': 45, 'end': 62}], 'document_id': '47328ddc339ebae5c939b3e8855babe8', 'meta': {}}>,\n",
              "   <Answer {'answer': 'transfer learning', 'type': 'extractive', 'score': 0.6531862020492554, 'context': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language pro\", 'offsets_in_document': [{'start': 45, 'end': 62}], 'offsets_in_context': [{'start': 45, 'end': 62}], 'document_id': 'e649d989b13e974f0f776ab654e4ab8c', 'meta': {}}>,\n",
              "   <Answer {'answer': 'Colossal Clean Crawled Corpus', 'type': 'extractive', 'score': 0.5289027690887451, 'context': 'ng the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks c', 'offsets_in_document': [{'start': 73, 'end': 102}], 'offsets_in_context': [{'start': 61, 'end': 90}], 'document_id': 'edbc99799fb9be68387e77036a3f0948', 'meta': {}}>,\n",
              "   <Answer {'answer': 'pretraining objectives, narchitectures, unlabeled datasets, transfer approaches', 'type': 'extractive', 'score': 0.1686444729566574, 'context': \"['Our systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of langua\", 'offsets_in_document': [{'start': 32, 'end': 111}], 'offsets_in_context': [{'start': 32, 'end': 111}], 'document_id': '38d44c154443032074664b80c667671', 'meta': {}}>],\n",
              "  'documents': [<Document: {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'd739f09f9bab640e5cec953a5b98bd6a'}>,\n",
              "   <Document: {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).', 'In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '62577fb39bdcb637b47e823dabf6c45b'}>,\n",
              "   <Document: {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'e649d989b13e974f0f776ab654e4ab8c'}>,\n",
              "   <Document: {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '47328ddc339ebae5c939b3e8855babe8'}>,\n",
              "   <Document: {'content': \"['Our systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '38d44c154443032074664b80c667671'}>,\n",
              "   <Document: {'content': \"['By combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks covering summarization, question answering, ntext classification, and more.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'edbc99799fb9be68387e77036a3f0948'}>],\n",
              "  'root_node': 'Query',\n",
              "  'params': {},\n",
              "  'node_id': 'Reader'},\n",
              " {'query': 'What did the paper introduce to explore the landscape of transfer learning techniques for NLP?',\n",
              "  'no_ans_gap': 11.940932035446167,\n",
              "  'answers': [<Answer {'answer': 'a unified framework', 'type': 'extractive', 'score': 0.7010067105293274, 'context': ' landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format', 'offsets_in_document': [{'start': 97, 'end': 116}], 'offsets_in_context': [{'start': 66, 'end': 85}], 'document_id': '47328ddc339ebae5c939b3e8855babe8', 'meta': {}}>,\n",
              "   <Answer {'answer': 'a unified framework', 'type': 'extractive', 'score': 0.6524139642715454, 'context': ' landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format', 'offsets_in_document': [{'start': 295, 'end': 314}], 'offsets_in_context': [{'start': 66, 'end': 85}], 'document_id': '62577fb39bdcb637b47e823dabf6c45b', 'meta': {}}>,\n",
              "   <Answer {'answer': 'a unified framework', 'type': 'extractive', 'score': 0.643170952796936, 'context': ' landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format', 'offsets_in_document': [{'start': 97, 'end': 116}], 'offsets_in_context': [{'start': 66, 'end': 85}], 'document_id': 'e649d989b13e974f0f776ab654e4ab8c', 'meta': {}}>,\n",
              "   <Answer {'answer': 'Colossal Clean Crawled Corpus', 'type': 'extractive', 'score': 0.3922332525253296, 'context': 'ng the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks c', 'offsets_in_document': [{'start': 73, 'end': 102}], 'offsets_in_context': [{'start': 61, 'end': 90}], 'document_id': 'edbc99799fb9be68387e77036a3f0948', 'meta': {}}>,\n",
              "   <Answer {'answer': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task\", 'type': 'extractive', 'score': 0.24657797813415527, 'context': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful t\", 'offsets_in_document': [{'start': 0, 'end': 121}], 'offsets_in_context': [{'start': 0, 'end': 121}], 'document_id': 'd739f09f9bab640e5cec953a5b98bd6a', 'meta': {}}>,\n",
              "   <Answer {'answer': 'pretraining objectives, narchitectures, unlabeled datasets', 'type': 'extractive', 'score': 0.0978536605834961, 'context': \"['Our systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of langua\", 'offsets_in_document': [{'start': 32, 'end': 90}], 'offsets_in_context': [{'start': 32, 'end': 90}], 'document_id': '38d44c154443032074664b80c667671', 'meta': {}}>],\n",
              "  'documents': [<Document: {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'e649d989b13e974f0f776ab654e4ab8c'}>,\n",
              "   <Document: {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '47328ddc339ebae5c939b3e8855babe8'}>,\n",
              "   <Document: {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).', 'In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '62577fb39bdcb637b47e823dabf6c45b'}>,\n",
              "   <Document: {'content': \"['By combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks covering summarization, question answering, ntext classification, and more.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'edbc99799fb9be68387e77036a3f0948'}>,\n",
              "   <Document: {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'd739f09f9bab640e5cec953a5b98bd6a'}>,\n",
              "   <Document: {'content': \"['Our systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '38d44c154443032074664b80c667671'}>],\n",
              "  'root_node': 'Query',\n",
              "  'params': {},\n",
              "  'node_id': 'Reader'},\n",
              " {'query': 'What has the effectiveness of transfer learning given rise to?',\n",
              "  'no_ans_gap': 10.461122989654541,\n",
              "  'answers': [<Answer {'answer': 'a diversity of approaches, methodology, and practice', 'type': 'extractive', 'score': 0.7925986647605896, 'context': \"ctiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice.', 'To facilitate future work on transfer learni\", 'offsets_in_document': [{'start': 441, 'end': 493}], 'offsets_in_context': [{'start': 49, 'end': 101}], 'document_id': '62577fb39bdcb637b47e823dabf6c45b', 'meta': {}}>,\n",
              "   <Answer {'answer': 'a powerful technique in natural language processing', 'type': 'extractive', 'score': 0.47604405879974365, 'context': \"trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).']\", 'offsets_in_document': [{'start': 138, 'end': 189}], 'offsets_in_context': [{'start': 90, 'end': 141}], 'document_id': 'd739f09f9bab640e5cec953a5b98bd6a', 'meta': {}}>,\n",
              "   <Answer {'answer': 'state-of-the-art', 'type': 'extractive', 'score': 0.3342510759830475, 'context': 'ith scale and our new “Colossal Clean Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks covering summarization, question answer', 'offsets_in_document': [{'start': 117, 'end': 133}], 'offsets_in_context': [{'start': 67, 'end': 83}], 'document_id': 'edbc99799fb9be68387e77036a3f0948', 'meta': {}}>,\n",
              "   <Answer {'answer': 'converts every language problem into a text-to-text format', 'type': 'extractive', 'score': 0.056002870202064514, 'context': \"ndscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.']\", 'offsets_in_document': [{'start': 123, 'end': 181}], 'offsets_in_context': [{'start': 89, 'end': 147}], 'document_id': 'e649d989b13e974f0f776ab654e4ab8c', 'meta': {}}>,\n",
              "   <Answer {'answer': \"nthat converts every language problem into a text-to-text format.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code\", 'type': 'extractive', 'score': 0.01798928529024124, 'context': \"nthat converts every language problem into a text-to-text format.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code\", 'offsets_in_document': [{'start': 117, 'end': 295}], 'offsets_in_context': [{'start': 0, 'end': 178}], 'document_id': '47328ddc339ebae5c939b3e8855babe8', 'meta': {}}>,\n",
              "   <Answer {'answer': 'language understanding tasks', 'type': 'extractive', 'score': 0.002882179105654359, 'context': \"mpares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks.']\", 'offsets_in_document': [{'start': 144, 'end': 172}], 'offsets_in_context': [{'start': 119, 'end': 147}], 'document_id': '38d44c154443032074664b80c667671', 'meta': {}}>],\n",
              "  'documents': [<Document: {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).', 'In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '62577fb39bdcb637b47e823dabf6c45b'}>,\n",
              "   <Document: {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '47328ddc339ebae5c939b3e8855babe8'}>,\n",
              "   <Document: {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'e649d989b13e974f0f776ab654e4ab8c'}>,\n",
              "   <Document: {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'd739f09f9bab640e5cec953a5b98bd6a'}>,\n",
              "   <Document: {'content': \"['By combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks covering summarization, question answering, ntext classification, and more.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'edbc99799fb9be68387e77036a3f0948'}>,\n",
              "   <Document: {'content': \"['Our systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '38d44c154443032074664b80c667671'}>],\n",
              "  'root_node': 'Query',\n",
              "  'params': {},\n",
              "  'node_id': 'Reader'},\n",
              " {'query': 'What do we do to facilitate future work on transfer learning for NLP?',\n",
              "  'no_ans_gap': 9.838558197021484,\n",
              "  'answers': [<Answer {'answer': 'release our dataset, pre-trained models, and code', 'type': 'extractive', 'score': 0.7645387053489685, 'context': \"roblem into a text-to-text format.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'offsets_in_document': [{'start': 246, 'end': 295}], 'offsets_in_context': [{'start': 98, 'end': 147}], 'document_id': '47328ddc339ebae5c939b3e8855babe8', 'meta': {}}>,\n",
              "   <Answer {'answer': 'release our dataset, pre-trained models, and code', 'type': 'extractive', 'score': 0.7257298231124878, 'context': \"oaches, methodology, and practice.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'offsets_in_document': [{'start': 558, 'end': 607}], 'offsets_in_context': [{'start': 98, 'end': 147}], 'document_id': '62577fb39bdcb637b47e823dabf6c45b', 'meta': {}}>,\n",
              "   <Answer {'answer': 'introducing a unified framework nthat converts every language problem into a text-to-text format', 'type': 'extractive', 'score': 0.3526579737663269, 'context': \"ndscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.']\", 'offsets_in_document': [{'start': 85, 'end': 181}], 'offsets_in_context': [{'start': 51, 'end': 147}], 'document_id': 'e649d989b13e974f0f776ab654e4ab8c', 'meta': {}}>,\n",
              "   <Answer {'answer': 'pre-trained on a data-rich task before being fine-tuned non a downstream task', 'type': 'extractive', 'score': 0.1837630569934845, 'context': 'fer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful techniqu', 'offsets_in_document': [{'start': 44, 'end': 121}], 'offsets_in_context': [{'start': 37, 'end': 114}], 'document_id': 'd739f09f9bab640e5cec953a5b98bd6a', 'meta': {}}>,\n",
              "   <Answer {'answer': 'combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus', 'type': 'extractive', 'score': 0.08027642965316772, 'context': \"['By combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, nwe achieve state-of-the-art results on many \", 'offsets_in_document': [{'start': 5, 'end': 102}], 'offsets_in_context': [{'start': 5, 'end': 102}], 'document_id': 'edbc99799fb9be68387e77036a3f0948', 'meta': {}}>,\n",
              "   <Answer {'answer': 'compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches', 'type': 'extractive', 'score': 0.011094960384070873, 'context': \"['Our systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of langua\", 'offsets_in_document': [{'start': 23, 'end': 111}], 'offsets_in_context': [{'start': 23, 'end': 111}], 'document_id': '38d44c154443032074664b80c667671', 'meta': {}}>],\n",
              "  'documents': [<Document: {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '47328ddc339ebae5c939b3e8855babe8'}>,\n",
              "   <Document: {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).', 'In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '62577fb39bdcb637b47e823dabf6c45b'}>,\n",
              "   <Document: {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'e649d989b13e974f0f776ab654e4ab8c'}>,\n",
              "   <Document: {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'd739f09f9bab640e5cec953a5b98bd6a'}>,\n",
              "   <Document: {'content': \"['Our systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '38d44c154443032074664b80c667671'}>,\n",
              "   <Document: {'content': \"['By combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks covering summarization, question answering, ntext classification, and more.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'edbc99799fb9be68387e77036a3f0948'}>],\n",
              "  'root_node': 'Query',\n",
              "  'params': {},\n",
              "  'node_id': 'Reader'},\n",
              " {'query': 'What do systematic studies compare on dozens of language understanding tasks?',\n",
              "  'no_ans_gap': 4.92225193977356,\n",
              "  'answers': [<Answer {'answer': 'pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors', 'type': 'extractive', 'score': 0.6625470519065857, 'context': 'systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of language und', 'offsets_in_document': [{'start': 32, 'end': 130}], 'offsets_in_context': [{'start': 26, 'end': 124}], 'document_id': '38d44c154443032074664b80c667671', 'meta': {}}>,\n",
              "   <Answer {'answer': 'state-of-the-art results', 'type': 'extractive', 'score': 0.370378702878952, 'context': 'scale and our new “Colossal Clean Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks covering summarization, question answering,', 'offsets_in_document': [{'start': 117, 'end': 141}], 'offsets_in_context': [{'start': 63, 'end': 87}], 'document_id': 'edbc99799fb9be68387e77036a3f0948', 'meta': {}}>,\n",
              "   <Answer {'answer': 'transfer learning techniques', 'type': 'extractive', 'score': 0.21732425689697266, 'context': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language pro\", 'offsets_in_document': [{'start': 45, 'end': 73}], 'offsets_in_context': [{'start': 45, 'end': 73}], 'document_id': 'e649d989b13e974f0f776ab654e4ab8c', 'meta': {}}>,\n",
              "   <Answer {'answer': 'transfer learning techniques', 'type': 'extractive', 'score': 0.1583271026611328, 'context': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language pro\", 'offsets_in_document': [{'start': 45, 'end': 73}], 'offsets_in_context': [{'start': 45, 'end': 73}], 'document_id': '47328ddc339ebae5c939b3e8855babe8', 'meta': {}}>,\n",
              "   <Answer {'answer': 'Transfer learning', 'type': 'extractive', 'score': 0.043506477028131485, 'context': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful t\", 'offsets_in_document': [{'start': 2, 'end': 19}], 'offsets_in_context': [{'start': 2, 'end': 19}], 'document_id': 'd739f09f9bab640e5cec953a5b98bd6a', 'meta': {}}>,\n",
              "   <Answer {'answer': 'Transfer learning', 'type': 'extractive', 'score': 0.005629844963550568, 'context': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful t\", 'offsets_in_document': [{'start': 2, 'end': 19}], 'offsets_in_context': [{'start': 2, 'end': 19}], 'document_id': '62577fb39bdcb637b47e823dabf6c45b', 'meta': {}}>],\n",
              "  'documents': [<Document: {'content': \"['Our systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '38d44c154443032074664b80c667671'}>,\n",
              "   <Document: {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).', 'In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '62577fb39bdcb637b47e823dabf6c45b'}>,\n",
              "   <Document: {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '47328ddc339ebae5c939b3e8855babe8'}>,\n",
              "   <Document: {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'e649d989b13e974f0f776ab654e4ab8c'}>,\n",
              "   <Document: {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'd739f09f9bab640e5cec953a5b98bd6a'}>,\n",
              "   <Document: {'content': \"['By combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks covering summarization, question answering, ntext classification, and more.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'edbc99799fb9be68387e77036a3f0948'}>],\n",
              "  'root_node': 'Query',\n",
              "  'params': {},\n",
              "  'node_id': 'Reader'},\n",
              " {'query': 'What do systematic studies compare on dozens of language understanding tasks?',\n",
              "  'no_ans_gap': 4.92225193977356,\n",
              "  'answers': [<Answer {'answer': 'pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors', 'type': 'extractive', 'score': 0.6625470519065857, 'context': 'systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of language und', 'offsets_in_document': [{'start': 32, 'end': 130}], 'offsets_in_context': [{'start': 26, 'end': 124}], 'document_id': '38d44c154443032074664b80c667671', 'meta': {}}>,\n",
              "   <Answer {'answer': 'state-of-the-art results', 'type': 'extractive', 'score': 0.370378702878952, 'context': 'scale and our new “Colossal Clean Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks covering summarization, question answering,', 'offsets_in_document': [{'start': 117, 'end': 141}], 'offsets_in_context': [{'start': 63, 'end': 87}], 'document_id': 'edbc99799fb9be68387e77036a3f0948', 'meta': {}}>,\n",
              "   <Answer {'answer': 'transfer learning techniques', 'type': 'extractive', 'score': 0.21732425689697266, 'context': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language pro\", 'offsets_in_document': [{'start': 45, 'end': 73}], 'offsets_in_context': [{'start': 45, 'end': 73}], 'document_id': 'e649d989b13e974f0f776ab654e4ab8c', 'meta': {}}>,\n",
              "   <Answer {'answer': 'transfer learning techniques', 'type': 'extractive', 'score': 0.1583271026611328, 'context': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language pro\", 'offsets_in_document': [{'start': 45, 'end': 73}], 'offsets_in_context': [{'start': 45, 'end': 73}], 'document_id': '47328ddc339ebae5c939b3e8855babe8', 'meta': {}}>,\n",
              "   <Answer {'answer': 'Transfer learning', 'type': 'extractive', 'score': 0.043506477028131485, 'context': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful t\", 'offsets_in_document': [{'start': 2, 'end': 19}], 'offsets_in_context': [{'start': 2, 'end': 19}], 'document_id': 'd739f09f9bab640e5cec953a5b98bd6a', 'meta': {}}>,\n",
              "   <Answer {'answer': 'Transfer learning', 'type': 'extractive', 'score': 0.005629844963550568, 'context': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful t\", 'offsets_in_document': [{'start': 2, 'end': 19}], 'offsets_in_context': [{'start': 2, 'end': 19}], 'document_id': '62577fb39bdcb637b47e823dabf6c45b', 'meta': {}}>],\n",
              "  'documents': [<Document: {'content': \"['Our systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '38d44c154443032074664b80c667671'}>,\n",
              "   <Document: {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).', 'In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '62577fb39bdcb637b47e823dabf6c45b'}>,\n",
              "   <Document: {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '47328ddc339ebae5c939b3e8855babe8'}>,\n",
              "   <Document: {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'e649d989b13e974f0f776ab654e4ab8c'}>,\n",
              "   <Document: {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'd739f09f9bab640e5cec953a5b98bd6a'}>,\n",
              "   <Document: {'content': \"['By combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks covering summarization, question answering, ntext classification, and more.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'edbc99799fb9be68387e77036a3f0948'}>],\n",
              "  'root_node': 'Query',\n",
              "  'params': {},\n",
              "  'node_id': 'Reader'},\n",
              " {'query': 'What are some benchmarks nwe achieve?',\n",
              "  'no_ans_gap': 7.295330047607422,\n",
              "  'answers': [<Answer {'answer': 'summarization, question answering, ntext classification, and more', 'type': 'extractive', 'score': 0.6816216707229614, 'context': \"Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks covering summarization, question answering, ntext classification, and more.']\", 'offsets_in_document': [{'start': 170, 'end': 235}], 'offsets_in_context': [{'start': 82, 'end': 147}], 'document_id': 'edbc99799fb9be68387e77036a3f0948', 'meta': {}}>,\n",
              "   <Answer {'answer': 'pretraining objectives, narchitectures, unlabeled datasets', 'type': 'extractive', 'score': 0.22290781140327454, 'context': \"['Our systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of langua\", 'offsets_in_document': [{'start': 32, 'end': 90}], 'offsets_in_context': [{'start': 32, 'end': 90}], 'document_id': '38d44c154443032074664b80c667671', 'meta': {}}>,\n",
              "   <Answer {'answer': 'Transfer learning', 'type': 'extractive', 'score': 0.021251607686281204, 'context': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful t\", 'offsets_in_document': [{'start': 2, 'end': 19}], 'offsets_in_context': [{'start': 2, 'end': 19}], 'document_id': 'd739f09f9bab640e5cec953a5b98bd6a', 'meta': {}}>,\n",
              "   <Answer {'answer': 'release our dataset, pre-trained models, and code', 'type': 'extractive', 'score': 0.01928706467151642, 'context': \"roblem into a text-to-text format.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'offsets_in_document': [{'start': 246, 'end': 295}], 'offsets_in_context': [{'start': 98, 'end': 147}], 'document_id': '47328ddc339ebae5c939b3e8855babe8', 'meta': {}}>,\n",
              "   <Answer {'answer': \"The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code\", 'type': 'extractive', 'score': 0.016191989183425903, 'context': \"'The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code\", 'offsets_in_document': [{'start': 384, 'end': 607}], 'offsets_in_context': [{'start': 1, 'end': 224}], 'document_id': '62577fb39bdcb637b47e823dabf6c45b', 'meta': {}}>,\n",
              "   <Answer {'answer': 'converts every language problem into a text-to-text format', 'type': 'extractive', 'score': 0.015526168048381805, 'context': \"ndscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.']\", 'offsets_in_document': [{'start': 123, 'end': 181}], 'offsets_in_context': [{'start': 89, 'end': 147}], 'document_id': 'e649d989b13e974f0f776ab654e4ab8c', 'meta': {}}>],\n",
              "  'documents': [<Document: {'content': \"['By combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks covering summarization, question answering, ntext classification, and more.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'edbc99799fb9be68387e77036a3f0948'}>,\n",
              "   <Document: {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '47328ddc339ebae5c939b3e8855babe8'}>,\n",
              "   <Document: {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).', 'In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '62577fb39bdcb637b47e823dabf6c45b'}>,\n",
              "   <Document: {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'd739f09f9bab640e5cec953a5b98bd6a'}>,\n",
              "   <Document: {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'e649d989b13e974f0f776ab654e4ab8c'}>,\n",
              "   <Document: {'content': \"['Our systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '38d44c154443032074664b80c667671'}>],\n",
              "  'root_node': 'Query',\n",
              "  'params': {},\n",
              "  'node_id': 'Reader'},\n",
              " {'query': 'What are some benchmarks nwe achieve?',\n",
              "  'no_ans_gap': 7.295330047607422,\n",
              "  'answers': [<Answer {'answer': 'summarization, question answering, ntext classification, and more', 'type': 'extractive', 'score': 0.6816216707229614, 'context': \"Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks covering summarization, question answering, ntext classification, and more.']\", 'offsets_in_document': [{'start': 170, 'end': 235}], 'offsets_in_context': [{'start': 82, 'end': 147}], 'document_id': 'edbc99799fb9be68387e77036a3f0948', 'meta': {}}>,\n",
              "   <Answer {'answer': 'pretraining objectives, narchitectures, unlabeled datasets', 'type': 'extractive', 'score': 0.22290781140327454, 'context': \"['Our systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of langua\", 'offsets_in_document': [{'start': 32, 'end': 90}], 'offsets_in_context': [{'start': 32, 'end': 90}], 'document_id': '38d44c154443032074664b80c667671', 'meta': {}}>,\n",
              "   <Answer {'answer': 'Transfer learning', 'type': 'extractive', 'score': 0.021251607686281204, 'context': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful t\", 'offsets_in_document': [{'start': 2, 'end': 19}], 'offsets_in_context': [{'start': 2, 'end': 19}], 'document_id': 'd739f09f9bab640e5cec953a5b98bd6a', 'meta': {}}>,\n",
              "   <Answer {'answer': 'release our dataset, pre-trained models, and code', 'type': 'extractive', 'score': 0.01928706467151642, 'context': \"roblem into a text-to-text format.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'offsets_in_document': [{'start': 246, 'end': 295}], 'offsets_in_context': [{'start': 98, 'end': 147}], 'document_id': '47328ddc339ebae5c939b3e8855babe8', 'meta': {}}>,\n",
              "   <Answer {'answer': \"The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code\", 'type': 'extractive', 'score': 0.016191989183425903, 'context': \"'The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code\", 'offsets_in_document': [{'start': 384, 'end': 607}], 'offsets_in_context': [{'start': 1, 'end': 224}], 'document_id': '62577fb39bdcb637b47e823dabf6c45b', 'meta': {}}>,\n",
              "   <Answer {'answer': 'converts every language problem into a text-to-text format', 'type': 'extractive', 'score': 0.015526168048381805, 'context': \"ndscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.']\", 'offsets_in_document': [{'start': 123, 'end': 181}], 'offsets_in_context': [{'start': 89, 'end': 147}], 'document_id': 'e649d989b13e974f0f776ab654e4ab8c', 'meta': {}}>],\n",
              "  'documents': [<Document: {'content': \"['By combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks covering summarization, question answering, ntext classification, and more.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'edbc99799fb9be68387e77036a3f0948'}>,\n",
              "   <Document: {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '47328ddc339ebae5c939b3e8855babe8'}>,\n",
              "   <Document: {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).', 'In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '62577fb39bdcb637b47e823dabf6c45b'}>,\n",
              "   <Document: {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'd739f09f9bab640e5cec953a5b98bd6a'}>,\n",
              "   <Document: {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'e649d989b13e974f0f776ab654e4ab8c'}>,\n",
              "   <Document: {'content': \"['Our systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '38d44c154443032074664b80c667671'}>],\n",
              "  'root_node': 'Query',\n",
              "  'params': {},\n",
              "  'node_id': 'Reader'},\n",
              " {'query': 'What are some benchmarks nwe achieve?',\n",
              "  'no_ans_gap': 7.295330047607422,\n",
              "  'answers': [<Answer {'answer': 'summarization, question answering, ntext classification, and more', 'type': 'extractive', 'score': 0.6816216707229614, 'context': \"Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks covering summarization, question answering, ntext classification, and more.']\", 'offsets_in_document': [{'start': 170, 'end': 235}], 'offsets_in_context': [{'start': 82, 'end': 147}], 'document_id': 'edbc99799fb9be68387e77036a3f0948', 'meta': {}}>,\n",
              "   <Answer {'answer': 'pretraining objectives, narchitectures, unlabeled datasets', 'type': 'extractive', 'score': 0.22290781140327454, 'context': \"['Our systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of langua\", 'offsets_in_document': [{'start': 32, 'end': 90}], 'offsets_in_context': [{'start': 32, 'end': 90}], 'document_id': '38d44c154443032074664b80c667671', 'meta': {}}>,\n",
              "   <Answer {'answer': 'Transfer learning', 'type': 'extractive', 'score': 0.021251607686281204, 'context': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful t\", 'offsets_in_document': [{'start': 2, 'end': 19}], 'offsets_in_context': [{'start': 2, 'end': 19}], 'document_id': 'd739f09f9bab640e5cec953a5b98bd6a', 'meta': {}}>,\n",
              "   <Answer {'answer': 'release our dataset, pre-trained models, and code', 'type': 'extractive', 'score': 0.01928706467151642, 'context': \"roblem into a text-to-text format.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'offsets_in_document': [{'start': 246, 'end': 295}], 'offsets_in_context': [{'start': 98, 'end': 147}], 'document_id': '47328ddc339ebae5c939b3e8855babe8', 'meta': {}}>,\n",
              "   <Answer {'answer': \"The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code\", 'type': 'extractive', 'score': 0.016191989183425903, 'context': \"'The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code\", 'offsets_in_document': [{'start': 384, 'end': 607}], 'offsets_in_context': [{'start': 1, 'end': 224}], 'document_id': '62577fb39bdcb637b47e823dabf6c45b', 'meta': {}}>,\n",
              "   <Answer {'answer': 'converts every language problem into a text-to-text format', 'type': 'extractive', 'score': 0.015526168048381805, 'context': \"ndscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.']\", 'offsets_in_document': [{'start': 123, 'end': 181}], 'offsets_in_context': [{'start': 89, 'end': 147}], 'document_id': 'e649d989b13e974f0f776ab654e4ab8c', 'meta': {}}>],\n",
              "  'documents': [<Document: {'content': \"['By combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, nwe achieve state-of-the-art results on many benchmarks covering summarization, question answering, ntext classification, and more.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'edbc99799fb9be68387e77036a3f0948'}>,\n",
              "   <Document: {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '47328ddc339ebae5c939b3e8855babe8'}>,\n",
              "   <Document: {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).', 'In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.', 'The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice.', 'To facilitate future work on transfer learning for NLP, nwe release our dataset, pre-trained models, and code.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '62577fb39bdcb637b47e823dabf6c45b'}>,\n",
              "   <Document: {'content': \"['Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned non a downstream task, has emerged as a powerful technique in natural language processing (NLP).']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'd739f09f9bab640e5cec953a5b98bd6a'}>,\n",
              "   <Document: {'content': \"['In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework nthat converts every language problem into a text-to-text format.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': 'e649d989b13e974f0f776ab654e4ab8c'}>,\n",
              "   <Document: {'content': \"['Our systematic study compares pretraining objectives, narchitectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks.']\", 'content_type': 'text', 'score': None, 'meta': {}, 'embedding': None, 'id': '38d44c154443032074664b80c667671'}>],\n",
              "  'root_node': 'Query',\n",
              "  'params': {},\n",
              "  'node_id': 'Reader'}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['answers'] = answers\n",
        "df"
      ],
      "metadata": {
        "id": "PevCBilH-QDR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "outputId": "9a6b6bc1-3d6b-4f0f-8e2f-91218bb746c8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           keyphrase  \\\n",
              "0                  transfer learning   \n",
              "1  natural language processing (nlp)   \n",
              "2                                nlp   \n",
              "3                       text-to-text   \n",
              "4             language understanding   \n",
              "5             pretraining objectives   \n",
              "6                             corpus   \n",
              "7                      summarization   \n",
              "8                 question answering   \n",
              "\n",
              "                                                                           context  \\\n",
              "0  ['Transfer learning, where a model is first pre-trained on a data-rich task ...   \n",
              "1  ['Transfer learning, where a model is first pre-trained on a data-rich task ...   \n",
              "2  ['In this paper, we explore the landscape of transfer learning techniques fo...   \n",
              "3  ['In this paper, we explore the landscape of transfer learning techniques fo...   \n",
              "4  ['Our systematic study compares pretraining objectives, narchitectures, unla...   \n",
              "5  ['Our systematic study compares pretraining objectives, narchitectures, unla...   \n",
              "6  ['By combining the insights from our exploration with scale and our new “Col...   \n",
              "7  ['By combining the insights from our exploration with scale and our new “Col...   \n",
              "8  ['By combining the insights from our exploration with scale and our new “Col...   \n",
              "\n",
              "                                                                          question  \\\n",
              "0         What has emerged as a powerful technique in natural language processing?   \n",
              "1  What did the paper introduce to explore the landscape of transfer learning t...   \n",
              "2                   What has the effectiveness of transfer learning given rise to?   \n",
              "3            What do we do to facilitate future work on transfer learning for NLP?   \n",
              "4    What do systematic studies compare on dozens of language understanding tasks?   \n",
              "5    What do systematic studies compare on dozens of language understanding tasks?   \n",
              "6                                            What are some benchmarks nwe achieve?   \n",
              "7                                            What are some benchmarks nwe achieve?   \n",
              "8                                            What are some benchmarks nwe achieve?   \n",
              "\n",
              "                                                                           answers  \n",
              "0  {'query': 'What has emerged as a powerful technique in natural language proc...  \n",
              "1  {'query': 'What did the paper introduce to explore the landscape of transfer...  \n",
              "2  {'query': 'What has the effectiveness of transfer learning given rise to?', ...  \n",
              "3  {'query': 'What do we do to facilitate future work on transfer learning for ...  \n",
              "4  {'query': 'What do systematic studies compare on dozens of language understa...  \n",
              "5  {'query': 'What do systematic studies compare on dozens of language understa...  \n",
              "6  {'query': 'What are some benchmarks nwe achieve?', 'no_ans_gap': 7.295330047...  \n",
              "7  {'query': 'What are some benchmarks nwe achieve?', 'no_ans_gap': 7.295330047...  \n",
              "8  {'query': 'What are some benchmarks nwe achieve?', 'no_ans_gap': 7.295330047...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4432448b-381e-49e8-afd1-c9b2f9e74fd8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keyphrase</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>transfer learning</td>\n",
              "      <td>['Transfer learning, where a model is first pre-trained on a data-rich task ...</td>\n",
              "      <td>What has emerged as a powerful technique in natural language processing?</td>\n",
              "      <td>{'query': 'What has emerged as a powerful technique in natural language proc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>natural language processing (nlp)</td>\n",
              "      <td>['Transfer learning, where a model is first pre-trained on a data-rich task ...</td>\n",
              "      <td>What did the paper introduce to explore the landscape of transfer learning t...</td>\n",
              "      <td>{'query': 'What did the paper introduce to explore the landscape of transfer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nlp</td>\n",
              "      <td>['In this paper, we explore the landscape of transfer learning techniques fo...</td>\n",
              "      <td>What has the effectiveness of transfer learning given rise to?</td>\n",
              "      <td>{'query': 'What has the effectiveness of transfer learning given rise to?', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>text-to-text</td>\n",
              "      <td>['In this paper, we explore the landscape of transfer learning techniques fo...</td>\n",
              "      <td>What do we do to facilitate future work on transfer learning for NLP?</td>\n",
              "      <td>{'query': 'What do we do to facilitate future work on transfer learning for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>language understanding</td>\n",
              "      <td>['Our systematic study compares pretraining objectives, narchitectures, unla...</td>\n",
              "      <td>What do systematic studies compare on dozens of language understanding tasks?</td>\n",
              "      <td>{'query': 'What do systematic studies compare on dozens of language understa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>pretraining objectives</td>\n",
              "      <td>['Our systematic study compares pretraining objectives, narchitectures, unla...</td>\n",
              "      <td>What do systematic studies compare on dozens of language understanding tasks?</td>\n",
              "      <td>{'query': 'What do systematic studies compare on dozens of language understa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>corpus</td>\n",
              "      <td>['By combining the insights from our exploration with scale and our new “Col...</td>\n",
              "      <td>What are some benchmarks nwe achieve?</td>\n",
              "      <td>{'query': 'What are some benchmarks nwe achieve?', 'no_ans_gap': 7.295330047...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>summarization</td>\n",
              "      <td>['By combining the insights from our exploration with scale and our new “Col...</td>\n",
              "      <td>What are some benchmarks nwe achieve?</td>\n",
              "      <td>{'query': 'What are some benchmarks nwe achieve?', 'no_ans_gap': 7.295330047...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>question answering</td>\n",
              "      <td>['By combining the insights from our exploration with scale and our new “Col...</td>\n",
              "      <td>What are some benchmarks nwe achieve?</td>\n",
              "      <td>{'query': 'What are some benchmarks nwe achieve?', 'no_ans_gap': 7.295330047...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4432448b-381e-49e8-afd1-c9b2f9e74fd8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4432448b-381e-49e8-afd1-c9b2f9e74fd8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4432448b-381e-49e8-afd1-c9b2f9e74fd8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-2SGryn3-lwK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}